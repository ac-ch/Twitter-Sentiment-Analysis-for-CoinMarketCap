{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis for Coinmarketcap\n",
    "\n",
    "Get the top 10 cryptocurrencies with Coinmarketcap APIs and analyse the user sentiments with Twitter APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for Coinmarketcap\n",
    "import urllib.request\n",
    "import json, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from coinmarketcap for each coin\n",
    "# define the Coinmarketcap API URL for top 10 coins\n",
    "# https://api.coinmarketcap.com/v2/ticker/?limit=10\n",
    "url = \"https://api.coinmarketcap.com/v2/ticker/?limit=10\"\n",
    "\n",
    "# open Coinmarketcap url\n",
    "page = urllib.request.urlopen(url)\n",
    "\n",
    "# read as JSON format the output\n",
    "data = json.loads(page.read()) # get the API answer as JSON (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 cryptos:\n",
      "Bitcoin | bitcoin\n",
      "Ethereum | ethereum\n",
      "XRP | ripple\n",
      "Bitcoin Cash | bitcoin-cash\n",
      "EOS | eos\n",
      "Stellar | stellar\n",
      "Litecoin | litecoin\n",
      "Cardano | cardano\n",
      "Tether | tether\n",
      "Monero | monero\n"
     ]
    }
   ],
   "source": [
    "# create a list with top crypto to search later in Twitter\n",
    "cryptos = []\n",
    "\n",
    "# append only the names and the website slug of each crypto\n",
    "for x, y in (data['data']).items():\n",
    "    cryptos.append((y['name'], y['website_slug']))\n",
    "    \n",
    "print('Top 10 cryptos:')\n",
    "for crypto in cryptos:\n",
    "    print(crypto[0],'|' , crypto[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HACK needed: tweepy will give you an error with some with python 3.7, so you need to repace 'async' variable with let's say 'tr_async' in \\Lib\\site-packages\\streaming.py!** (https://stackoverflow.com/questions/49339502/tweepy-on-macbook-pycharm-async-invalid-syntax)\n",
    "\n",
    "Thanks to the following projects:\n",
    "* https://www.youtube.com/watch?v=o_OZdbCzHUA&index=2&list=PL2-dafEMk2A6QKz1mrk1uIGfHkC1zZ6UU\n",
    "* https://github.com/llSourcell/twitter_sentiment_challenge/blob/master/demo.py\n",
    "* https://stackabuse.com/accessing-the-twitter-api-with-python/\n",
    "* https://github.com/shreyans29/thesemicolon/blob/master/livesenti.py\n",
    "* https://www.youtube.com/watch?v=l9AC98amjSA\n",
    "\n",
    "Let's use **tweepy** library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your Twitter API keys and secrets for consumer and access (https://stackabuse.com/accessing-the-twitter-api-with-python/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your keys/secrets as strings in the following fields\n",
    "credentials = {}  \n",
    "credentials['CONSUMER_KEY']    = 'YOUR DATA'  \n",
    "credentials['CONSUMER_SECRET'] = 'YOUR DATA'  \n",
    "credentials['ACCESS_TOKEN']    = 'YOUR DATA'  \n",
    "credentials['ACCESS_SECRET']   = 'YOUR DATA'\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open(\"twitter_credentials.json\", \"w\") as file:  \n",
    "    json.dump(credentials, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One call of tweets\n",
    "\n",
    "We will process only one time 15 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import re\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:  \n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Twitter sentiment analysis using only 15 tweets ...\n",
      "2018-11-03 03:02:40.985836\n",
      "                      crypto  polarity  subjectivity\n",
      "4                    EOS-eos  0.500000      0.900000\n",
      "8              Tether-tether  0.500000      0.900000\n",
      "6          Litecoin-litecoin  0.137500      0.387500\n",
      "1          Ethereum-ethereum  0.136364      0.454545\n",
      "5            Stellar-stellar  0.100000      0.325000\n",
      "0            Bitcoin-bitcoin  0.000000      1.000000\n",
      "2                 XRP-ripple  0.000000      1.000000\n",
      "3  Bitcoin Cash-bitcoin-cash  0.000000      0.000000\n",
      "9              Monero-monero  0.000000      0.000000\n",
      "7            Cardano-cardano       NaN           NaN\n",
      "\n",
      "* Max polarity:\n",
      "crypto          EOS-eos\n",
      "polarity            0.5\n",
      "subjectivity        0.9\n",
      "Name: 4, dtype: object\n",
      "\n",
      "* Max subjectivity:\n",
      "crypto          Bitcoin-bitcoin\n",
      "polarity                      0\n",
      "subjectivity                  1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "print('-> Twitter sentiment analysis using only 15 tweets ...')\n",
    "print(datetime.datetime.today())\n",
    "# create a dataframe with the mean values\n",
    "stats = []\n",
    "\n",
    "# analyse each crypto using one call of tweets\n",
    "for crypto in cryptos:\n",
    "    \n",
    "    # create search with 2 words: crypto name and website_slug\n",
    "    keywords = \" OR \".join(crypto)\n",
    "    # print('* Tweets for ',keywords)\n",
    "    \n",
    "    # Create our query\n",
    "    query = {'q': keywords,  \n",
    "            'result_type': 'popular',\n",
    "            #'count': 15,\n",
    "            'lang': 'en',\n",
    "            }\n",
    "\n",
    "    # create dictionary to retrive tweets info\n",
    "    dict_ = {'crypto': [], 'date': [], 'text': [], 'polarity': [], 'subjectivity': [], }  \n",
    "    \n",
    "    # Search tweets\n",
    "    for status in python_tweets.search(**query)['statuses']:\n",
    "        dict_['crypto'].append(keywords)      # type of crypto\n",
    "        dict_['date'].append(status['created_at']) # date\n",
    "        dict_['text'].append(status['text'])       # text of tweet\n",
    "        \n",
    "        # Perform Sentiment Analysis on Tweets\n",
    "        # ****************************************\n",
    "        # correct encoding\n",
    "        tweet = status['text'].encode(\"utf-8\")\n",
    "        # use only letters (eliminate strange characters)\n",
    "        tweet=\" \".join(re.findall(\"[a-zA-Z]+\", str(tweet)))\n",
    "        \n",
    "        analysis = TextBlob(tweet.strip())\n",
    "        sentiment = analysis.sentiment\n",
    "        dict_['polarity'] = sentiment.polarity         # evaluated polarity\n",
    "        dict_['subjectivity'] = sentiment.subjectivity # evaluated subjectivity\n",
    "\n",
    "    # Structure data in a pandas DataFrame for easier manipulation for one coin\n",
    "    df = pd.DataFrame(dict_)  \n",
    "    mean_polarity = df.loc[:,\"polarity\"].mean()\n",
    "    mean_subjectivity = df.loc[:,\"subjectivity\"].mean()\n",
    "    \n",
    "    # add the mean for each coint\n",
    "    stats.append((crypto[0]+'-'+crypto[1],float(mean_polarity),float(mean_subjectivity)))\n",
    "\n",
    "# create a dataframe for the mean values\n",
    "df_stats = pd.DataFrame(stats, columns=['crypto','polarity','subjectivity'])\n",
    "\n",
    "# Sort the results using polarity descending\n",
    "df_stats.sort_values(by='polarity', inplace=True, ascending=False)  \n",
    "\n",
    "# print means of the evaluations\n",
    "print(df_stats)\n",
    "\n",
    "print('\\n* Max polarity:')\n",
    "print(df_stats.loc[df_stats['polarity'].idxmax()])\n",
    "\n",
    "print('\\n* Max subjectivity:')\n",
    "print(df_stats.loc[df_stats['subjectivity'].idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have fun!\n",
    "\n",
    "2018@muntisa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
